{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ea6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d3e30",
   "metadata": {},
   "source": [
    "# Hunalign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b1cfa",
   "metadata": {},
   "source": [
    "### Text preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7346396",
   "metadata": {},
   "source": [
    "English text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('en.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    en_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e8b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ready = []\n",
    "for i in sent_tokenize(en_text):\n",
    "    en_ready.append('<p>')\n",
    "    en_ready.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618606f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('en_hunalign.txt', 'w', encoding='utf-8-sig') as f:\n",
    "    f.write('\\n'.join(en_ready))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2cdde0",
   "metadata": {},
   "source": [
    "Russian text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ru.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    ru_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05c6cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ru_ready = []\n",
    "for i in sent_tokenize(ru_text):\n",
    "    new_i = re.sub('([.,!?();])', r' \\1 ', i)\n",
    "    new_i = re.sub('\\s{2,}', ' ', new_i)\n",
    "    ru_ready.append('<p>')\n",
    "    ru_ready.append(new_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ru_hunalign.txt', 'w', encoding='utf-8-sig') as f:\n",
    "    f.write('\\n'.join(ru_ready))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1cc3e9",
   "metadata": {},
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fbc803",
   "metadata": {},
   "source": [
    "В папку с приложением hunalign.exe и нулевым словарем null.dic (так как для русского языка нет готового словаря) положить файлы en_demo и ru_demo, в которых находятся в готовом для элайнмента формате предложения на соответствующих языках, открыть в ней командную строку и ввести следующее (результат будет в файле hunalign.txt):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b667b",
   "metadata": {},
   "source": [
    "hunalign.exe null.dic en_hunalign.txt ru_hunalign.txt -text -utf -realign > hunalign.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094ea24",
   "metadata": {},
   "source": [
    "### Hunalign table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7981b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hunalign.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    aligned_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_p = aligned_text.split('\\n')\n",
    "\n",
    "without_p = []\n",
    "for i in range(1, len(with_p), 2):\n",
    "    without_p.append(with_p[i])\n",
    "\n",
    "en_hunalign_df = []\n",
    "for element in without_p:\n",
    "    for en in range(0, len(element.split('\\t')), 3):\n",
    "        en_hunalign_df.append(element.split('\\t')[en])\n",
    "\n",
    "ru_hunalign_df = []\n",
    "for element in without_p:\n",
    "    for ru in range(1, len(element.split('\\t')), 3):\n",
    "        ru_hunalign_df.append(element.split('\\t')[ru])\n",
    "\n",
    "score = []\n",
    "for element in without_p:\n",
    "    for sc in range(2, len(element.split('\\t')), 3):\n",
    "        score.append(element.split('\\t')[sc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hunalign = pd.DataFrame({'en': en_hunalign_df, 'ru': ru_hunalign_df, 'score': score})\n",
    "\n",
    "df_hunalign.to_excel('./hunalign.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2472ca9e",
   "metadata": {},
   "source": [
    "### Hunalign table with entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6513932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "\n",
    "for count, letter in enumerate(en_text):\n",
    "    if en_text[count-1]+letter == ' .' or letter == '?' or letter == '!':\n",
    "        points.append(count)\n",
    "\n",
    "for i, value in enumerate(en_hunalign_df):\n",
    "    if value == '':\n",
    "        points.insert(i, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entities = pd.read_excel('entities.xlsx', index_col=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f8e36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hunalign_entities = pd.DataFrame({'en': en_hunalign_df, 'ru': ru_hunalign_df, 'points': points, 'entities': ''*len(points)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf001c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "entities = [[] for _ in range(len(points))]\n",
    "\n",
    "for i, value in enumerate(df_entities[1]):\n",
    "    for ind, p in enumerate(points):\n",
    "        if p != '' and int(value.split(' ')[1]) < int(p):\n",
    "            entities[[df_hunalign_entities[df_hunalign_entities['points']==p].index.values][0][0]].append(str(value.split(' ')[0])+'-'+df_entities[2][i])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hunalign_entities = pd.DataFrame({'en': en_hunalign_df, 'ru': ru_hunalign_df, 'entities': entities})\n",
    "\n",
    "df_hunalign_entities.to_excel('./hunalign_entities.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caae2d4",
   "metadata": {},
   "source": [
    "# Fast_align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce870750",
   "metadata": {},
   "source": [
    "### Text preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e72757",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_en_text = []\n",
    "for sent in sent_tokenize(en_text.lower()):\n",
    "    tokenized_en_text.append(tokenizer.tokenize(sent))\n",
    "    \n",
    "clean_en_text = []\n",
    "for sent in tokenized_en_text:\n",
    "    clean_en_text.append(' '.join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1fd23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ru_text = []\n",
    "for sent in sent_tokenize(ru_text.lower(), language=\"russian\"):\n",
    "    tokenized_ru_text.append(tokenizer.tokenize(sent))\n",
    "\n",
    "clean_ru_text = []\n",
    "for sent in tokenized_ru_text:\n",
    "    clean_ru_text.append(' '.join(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4aefb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('en_fastalign.txt', 'w', encoding='utf-8-sig') as f:\n",
    "    f.write('\\n'.join(clean_en_text))\n",
    "\n",
    "with open('ru_fastalign.txt', 'w', encoding='utf-8-sig') as f:\n",
    "    f.write('\\n'.join(clean_ru_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d5fb92",
   "metadata": {},
   "source": [
    "### Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd0191",
   "metadata": {},
   "source": [
    "Через консоль Ubuntu. Сначала приведем в нужный формат по предложениям:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88eb9d9",
   "metadata": {},
   "source": [
    "paste en_fastalign.txt ru_fastalign.txt | sed \"s/$(printf '\\t')/ ||| /g\" > source_targets.fastalign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc59c1",
   "metadata": {},
   "source": [
    "Сначала мы рассматриваем английский язык как мишень (target), а русский язык как источник (source), поэтому используем reverse:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b30f1a",
   "metadata": {},
   "source": [
    "./fast_align -i source_targets.fastalign -d -o -v -r > reverse.align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70bc80",
   "metadata": {},
   "source": [
    "### Fast_align table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d12e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fastalign_en_ru.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    aligned_words = f.read()\n",
    "\n",
    "aligned_words = aligned_words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e93403",
   "metadata": {},
   "outputs": [],
   "source": [
    "sootnosh = []\n",
    "for i in range(len(aligned_words)-1):\n",
    "    sootnosh.append([[aligned_words[i]],[clean_en_text[i], clean_ru_text[i]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c57aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_fastalign_incomplete = pd.DataFrame({'en': [], 'ru': []}) #поменять местами для ru_en\n",
    "\n",
    "k = 0\n",
    "for soot in sootnosh:\n",
    "    indexes = soot[0][0].split(' ')\n",
    "    list_en = []\n",
    "    list_ru = []\n",
    "    \n",
    "    for i in indexes:\n",
    "        if soot[0][0] == '':\n",
    "            for j in range(len(soot[1][0].split(' '))):\n",
    "                list_en.append(soot[1][0].split(' ')[j])\n",
    "                list_ru.append('')\n",
    "        else:\n",
    "            list_en.append(soot[1][0].split(' ')[int(i.split('-')[0])])\n",
    "            list_ru.append(soot[1][1].split(' ')[int(i.split('-')[1])])     \n",
    "        \n",
    "    inde = [k]\n",
    "    df2 = pd.DataFrame(list(zip(inde, inde)), columns=['en', 'ru'])\n",
    "    df_fastalign_incomplete = df_fastalign_incomplete.append(df2)\n",
    "    df2 = pd.DataFrame(list(zip(list_en, list_ru)), columns=['en', 'ru']) # поменять местами list_en и list_ru для ru_en и columns\n",
    "    df_fastalign_incomplete = df_fastalign_incomplete.append(df2)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3415b26",
   "metadata": {},
   "source": [
    "### Fast_align complete table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fastalign_df = []\n",
    "for i in range(len(en_hunalign_df)):\n",
    "    new_str = str(i) + ' '\n",
    "    en_fastalign_df.append(new_str + en_hunalign_df[i])\n",
    "\n",
    "sentences = []\n",
    "for i in en_fastalign_df:\n",
    "    new_i = i.split(' ')\n",
    "    sentences.append(new_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648c5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_sentences = []\n",
    "incomplete_one_sent = []\n",
    "\n",
    "len_k = int(sentences[-1][0]) + 1\n",
    "k = 0\n",
    "for i in df_fastalign_incomplete['en']:\n",
    "    if i == k + 1:\n",
    "        incomplete_sentences.append(incomplete_one_sent)\n",
    "        incomplete_one_sent = []\n",
    "        k += 1\n",
    "        incomplete_one_sent.append(i)\n",
    "    else:\n",
    "        incomplete_one_sent.append(str(i))\n",
    "    \n",
    "incomplete_sentences.append(incomplete_one_sent)\n",
    "incomplete_sentences[0][0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb68a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pair = []\n",
    "incomplete = []\n",
    "\n",
    "k = 1\n",
    "minus_len = 0\n",
    "for i, value in enumerate(df_fastalign_incomplete['ru']):\n",
    "    if value == k:\n",
    "        incomplete.append(pair)\n",
    "        pair = []\n",
    "        minus_len += len(incomplete[k-1])\n",
    "        k += 1\n",
    "        \n",
    "    pair.append(str(incomplete_sentences[k-1][i-minus_len]) + '-' + str(value))\n",
    "\n",
    "incomplete.append(pair)\n",
    "incomplete[0][0] = '0-0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78abd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete = []\n",
    "\n",
    "for one_sent in sentences:\n",
    "    j = 0\n",
    "    pair = sentences.index(one_sent)\n",
    "    \n",
    "    for i in range(len(one_sent)):\n",
    "        \n",
    "        try:\n",
    "            if one_sent[i].lower() == incomplete[pair][j].split('-')[0]:\n",
    "                complete.append(incomplete[pair][j])\n",
    "                j += 1\n",
    "            elif one_sent[i].lower() == \"'s\" or one_sent[i].lower() == \"'d\":\n",
    "                complete.append(incomplete[pair][j])\n",
    "                j += 1\n",
    "            else:\n",
    "                complete.append(one_sent[i].lower() + '-' + ' ')\n",
    "        \n",
    "        except IndexError:\n",
    "            complete.append(one_sent[i].lower() + '-' + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fastalign_complete = []\n",
    "ru_fastalign_complete = []\n",
    "\n",
    "k = 0\n",
    "for pair in complete:\n",
    "    if pair.split('-')[0] == str(k) and pair.split('-')[1] == str(k):\n",
    "        en_fastalign_complete.append(int(pair.split('-')[0]))\n",
    "        ru_fastalign_complete.append(int(pair.split('-')[1]))\n",
    "        k += 1\n",
    "    else:\n",
    "        en_fastalign_complete.append(pair.split('-')[0])\n",
    "        ru_fastalign_complete.append(pair.split('-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3de88f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_fastalign_complete = pd.DataFrame({'en': en_fastalign_complete, 'ru': ru_fastalign_complete})\n",
    "df_fastalign_complete.to_excel('./fastalign_en_ru_complete.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для ru_en\n",
    "df_fastalign_complete = pd.DataFrame({'ru': ru_fastalign_complete, 'en': en_fastalign_complete})\n",
    "df_fastalign_complete.to_excel('./fastalign_ru_en_complete.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1d867",
   "metadata": {},
   "source": [
    "### Fast_align table with entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170590dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_tags = []\n",
    "\n",
    "k = 0\n",
    "full_word = ''\n",
    "for i, word in enumerate(df_fastalign_complete['en']):\n",
    "    \n",
    "    if type(word) != str and math.isnan(word):\n",
    "        word = ''\n",
    "        len_token = 2\n",
    "    elif word == 's' or word == 'd':\n",
    "        len_token = 2\n",
    "    else:\n",
    "        len_token = len(str(word))\n",
    "   \n",
    "    try:\n",
    "        k += len_token + 1\n",
    "        if (word == '.' or word == '!' or word == '?') and (len(str(df_fastalign_complete['en'][i + 1])) == 1 and str(df_fastalign_complete['en'][i + 1]).isdigit()):\n",
    "            k -= 2\n",
    "        elif (word == '.' or word == '!' or word == '?') and (len(str(df_fastalign_complete['en'][i + 1])) == 2 and str(df_fastalign_complete['en'][i + 1]).isdigit()):\n",
    "            k -= 3 \n",
    "        elif (word == '.' or word == '!' or word == '?') and (len(str(df_fastalign_complete['en'][i + 1])) == 3 and str(df_fastalign_complete['en'][i + 1]).isdigit()):\n",
    "            k -= 4\n",
    "\n",
    "        all_tags.append(str(word) + '-' + ' ')\n",
    "        for start in df_entities[1]:\n",
    "            if k - 2 > int(start.split(' ')[1]) and k - 2 <= int(start.split(' ')[2])+1 and word != '.' and word != '!' and word != '?':\n",
    "                fin = str(word) + '-' + start.split(' ')[0]\n",
    "                \n",
    "                if all_tags[len(all_tags) - 1].split('-')[0] == word and all_tags[len(all_tags) - 1].split('-')[1] == ' ':\n",
    "                    all_tags[len(all_tags) - 1] = fin\n",
    "                elif all_tags[len(all_tags) - 1].split('-')[0] == word and all_tags[len(all_tags) - 1].split('-')[1] != ' ':\n",
    "                    all_tags[len(all_tags) - 1] = all_tags[len(all_tags) - 1] + '-' + start.split(' ')[0]\n",
    "                else:\n",
    "                    all_tags.append(fin)\n",
    "                    \n",
    "    except KeyError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883d14c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "en_fastalign_entities = []\n",
    "fastalign_entities = []\n",
    "for i, value in enumerate(all_tags):\n",
    "    \n",
    "    en_fastalign_entities.append(value.split('-')[0])\n",
    "    if value.split('-')[1] == ' ':\n",
    "        fastalign_entities.append('')\n",
    "    else:\n",
    "        fastalign_entities.append(value.split('-')[1:])\n",
    "\n",
    "ru_fastalign_entities = list(df_fastalign_complete['ru'])\n",
    "en_fastalign_entities.append('.')\n",
    "fastalign_entities.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c81a15f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_fastalign_entities = pd.DataFrame({'en': en_fastalign_entities, 'ru': ru_fastalign_entities, 'tags': fastalign_entities})\n",
    "df_fastalign_entities.to_excel('./fastalign_en_ru_entities.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e0ac8b",
   "metadata": {},
   "source": [
    "### Ru_en fast_align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d48554a",
   "metadata": {},
   "source": [
    "Теперь проделываем то же самое, но рассматриваем русский язык как мишень (target), а английский как источник (source), используем forward:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55280a75",
   "metadata": {},
   "source": [
    "./fast_align -i source_targets.fastalign -d -o -v > forward.align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c871556",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fastalign_ru_en.txt', 'r', encoding='utf-8-sig') as f:\n",
    "    aligned_words = f.read()\n",
    "\n",
    "aligned_words = aligned_words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c4eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tags = {}\n",
    "list_dict_tags = []\n",
    "\n",
    "k = 1\n",
    "for i, word in enumerate(df_fastalign_entities['en']):\n",
    "    \n",
    "    if word == str(k) and df_fastalign_entities['ru'][i] == k:\n",
    "        list_dict_tags.append(dict_tags)\n",
    "        dict_tags = {}\n",
    "        k += 1\n",
    "        \n",
    "    elif df_fastalign_entities['tags'][i] in dict_tags.keys() and type(df_fastalign_entities['tags'][i]) == str:\n",
    "        dict_tags[df_fastalign_entities['tags'][i]].append(word)\n",
    "        \n",
    "    elif type(df_fastalign_entities['tags'][i]) == str:\n",
    "        dict_tags[df_fastalign_entities['tags'][i]] = [word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdebd07",
   "metadata": {},
   "source": [
    "Проделать sootnosh для ru_en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4997c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ru_fastalign_entities = []\n",
    "en_fastalign_entities = []\n",
    "fastalign_entities = []\n",
    "\n",
    "k = 0\n",
    "for i, word in enumerate(df_fastalign_incomplete['en']):\n",
    "    ru_fastalign_entities.append(df_fastalign_incomplete['ru'][i])\n",
    "    en_fastalign_entities.append(word)\n",
    "    \n",
    "    if word == k + 1 and df_fastalign_incomplete['ru'][i] == k + 1:\n",
    "        k += 1\n",
    "    \n",
    "    for key, value in list_dict_tags[k].items():\n",
    "        for v in value:\n",
    "            if word == v:\n",
    "                fastalign_entities.append(key)\n",
    "                break\n",
    "                \n",
    "    if len(en_fastalign_entities) > len(fastalign_entities):\n",
    "        fastalign_entities.append('')\n",
    "if len(en_fastalign_entities) > len(fastalign_entities):\n",
    "    fastalign_entities.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393752f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_fastalign_entities = pd.DataFrame({'ru': ru_fastalign_entities, 'en': en_fastalign_entities, 'tags': fastalign_entities})\n",
    "df_fastalign_entities.to_excel('./fastalign_ru_en_entities.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40b0e5",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfb5fb0",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c833d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fastalign_entities = pd.read_excel('fastalign_ru_en_entities.xlsx', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1e410170",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = []\n",
    "\n",
    "k = 0\n",
    "for i, line in enumerate(df_fastalign_entities['ru']):\n",
    "\n",
    "    if str(df_fastalign_entities['tags'][i]) == 'nan':\n",
    "        tag = ''\n",
    "    else:\n",
    "        tag = df_fastalign_entities['tags'][i]\n",
    "        \n",
    "    if line == k and df_fastalign_entities['en'][i] == k:\n",
    "        dictionary.append(str(k) + '-' + str(k) + '-' + tag)\n",
    "        k += 1\n",
    "    else:\n",
    "        dictionary.append(str(line) + '-' + str(df_fastalign_entities['en'][i]) + '-' + tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f0adbb15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ru_hunalign_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [130]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m for_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mru_hunalign_df\u001b[49m:\n\u001b[0;32m      3\u001b[0m     for_models \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m for_models \u001b[38;5;241m=\u001b[39m for_models\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ru_hunalign_df' is not defined"
     ]
    }
   ],
   "source": [
    "for_models = ''\n",
    "for i in ru_hunalign_df:\n",
    "    for_models += i + ' '\n",
    "    \n",
    "for_models = for_models.replace('?', '.')\n",
    "for_models = for_models.replace('!', '.')\n",
    "for_models = for_models.replace('~~~', '')\n",
    "for_models = for_models.replace('. . .', '')\n",
    "\n",
    "new_for_models = []\n",
    "k = 0\n",
    "for i in for_models.split('.'):\n",
    "    new_i = re.sub(r'[.«»,\"\\'?:!;—]', '', i)\n",
    "    new_i = re.sub(r'[-]', ' ', new_i)\n",
    "    new_i = re.sub(r'[\\n\\xa0]', ' ', new_i)\n",
    "    new_i = re.sub(r'  ', ' ', new_i)\n",
    "    if k == 0:\n",
    "        new_for_models.append(str(k) + ' ' + new_i)\n",
    "    else:\n",
    "        new_for_models.append(str(k) + new_i)\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76737ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for_models = ''\n",
    "for i in new_for_models:\n",
    "    for_models += '' + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9a1029ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fastalign_entities_complete = []\n",
    "\n",
    "k = 0\n",
    "j = 0\n",
    "for word in for_models.split(' '):\n",
    "    \n",
    "    if word.lower() != dictionary[j].split('-')[0]:\n",
    "        df_fastalign_entities_complete.append(word.lower() + '-' + '' + '-' + '')\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        df_fastalign_entities_complete.append(dictionary[j].split('-')[0] + '-' + dictionary[j].split('-')[1] + '-' + dictionary[j].split('-')[2])\n",
    "        j += 1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34da800",
   "metadata": {},
   "source": [
    "### Natasha Slovnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c86f8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "from slovnet import NER\n",
    "\n",
    "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\n",
    "ner = NER.load('slovnet_ner_news_v1.tar')\n",
    "ner.navec(navec)\n",
    "\n",
    "natasha_slovnet = ner(for_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "18493031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_natasha = []\n",
    "\n",
    "length = 0\n",
    "for i in range(len(df_fastalign_entities_complete)):\n",
    "    length += len(df_fastalign_entities_complete[i].split('-')[0]) + 1\n",
    "    \n",
    "    for j in natasha_slovnet.spans:\n",
    "        tag = ''\n",
    "        if length >= j.start and length <= j.stop:\n",
    "            tag = j.type\n",
    "            break\n",
    "    \n",
    "    try:\n",
    "        new_tag = df_fastalign_entities_complete[i + 1] + '-' + tag\n",
    "        df_natasha.append(new_tag)\n",
    "    except IndexError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3a674a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_full_tags = []\n",
    "en_full_tags = []\n",
    "en_tag_full_tags = []\n",
    "natasha = []\n",
    "\n",
    "for i in df_natasha:\n",
    "    ru_full_tags.append(i.split('-')[0])\n",
    "    en_full_tags.append(i.split('-')[1])\n",
    "    en_tag_full_tags.append(i.split('-')[2][2:5])\n",
    "    natasha.append(i.split('-')[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c7322",
   "metadata": {},
   "source": [
    "### Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0c761d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 16:02:33 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0927312332b48b28dcf5daa41f61a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 16:02:40 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| ner       | wikiner   |\n",
      "=========================\n",
      "\n",
      "2023-05-18 16:02:40 INFO: Use device: cpu\n",
      "2023-05-18 16:02:40 INFO: Loading: tokenize\n",
      "2023-05-18 16:02:41 INFO: Loading: ner\n",
      "2023-05-18 16:02:45 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang='ru', processors='tokenize,ner')\n",
    "doc_stanza = nlp(for_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "29f28e95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stanza = []\n",
    "\n",
    "length = 0\n",
    "for i in range(len(df_fastalign_entities_complete)):\n",
    "    length += len(df_fastalign_entities_complete[i].split('-')[0]) + 1\n",
    "\n",
    "    for sent in doc_stanza.sentences:\n",
    "        for ent in sent.ents:\n",
    "            tag = ''\n",
    "            if length >= ent.start_char and length <= ent.end_char:\n",
    "                tag = ent.type\n",
    "                break\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        new_tag = df_fastalign_entities_complete[i + 1] + '-' + tag\n",
    "        df_stanza.append(new_tag)\n",
    "    except IndexError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "9c68859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza = []\n",
    "for i in df_stanza:\n",
    "    stanza.append(i.split('-')[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6644b62e",
   "metadata": {},
   "source": [
    "### Deeppavlov RuBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bcd9e33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for_models = '0 Однажды давным давно в старое доброе время шла по дороге коровушка Му му шла и шла и встретила на дороге хорошенького прехорошенького мальчика а звали его Бу бу Папа рассказывал ему эту сказку папа смотрел на него через стеклышко 1 У него было волосатое лицо 2 Он был мальчик Бу бу 3 Му му шла по дороге где жила Бетти Берн она продавала лимонные леденцы 4 О цветы дикой розыНа зеленом лугу 5 Он пел эту песню 6 Это была его песня 7 О таритатам лозы Когда намочишь в постельку сначала делается горячо а потом холодно 8 Мама подкладывает клеенку 9 От нее такой чудной запах 10 От мамы пахнет приятнее чем от папы 11 Она играет ему на рояле матросский танец чтобы он плясал 12 Он плясал Тра ля ля ля ля Тра ля ля тра ля ля ди Тра ля ля ля ля Тра ля ля ля ля Дядя Чарльз и Дэнти хлопали в ладоши 13 Они старее папы и мамы но дядя Чарльз еще старее Дэнти 14 У Дэнти в шкафу две щетки 15 Щетка с коричневой бархатной спинкой в честь Майкла Дэвитта а щетка с зеленой бархатной спинкой в честь Парнелла 16 Дэнти давала ему мятный леденец всякий раз когда он приносил ей бумажную салфетку 17 Вэнсы жили в доме семь 18 У них другие папы и мамы 19 Это папа и мама Эйлин 20 Когда они вырастут большие он женится на Эйлин 21 Он спрятался под стол 22 Мама сказала 23 Проси прощенья Стивен 24 Дэнти сказала  А не попросишь прилетит орел и выклюет тебе глаза 25 И выклюет тебе глаза Проси прощенья егоза Проси прощенья егоза И выклюет тебе глаза Проси прощенья егоза И выклюет тебе глаза И выклюет тебе глаза Проси прощенья егоза 26 * На больших спортивных площадках толпились мальчики 27 Все кричали и воспитатели их громко подбадривали 28 Вечерний воздух был бледный и прохладный и после каждой атаки и удара футболистов лоснящийся кожаный шар как тяжелая птица взлетал в сером свете 29 Он топтался в самом хвосте своей команды подальше от воспитателя подальше от грубых ног и время от времени делал вид что бегает 30 Он чувствовал себя маленьким и слабым среди толпы играющих и глаза у него были слабые и слезились 31 Роди Кикем не такой он будет капитаном третьей команды говорили мальчики 32 Роди Кикем хороший мальчик а Вонючка Роуч противный 33 У Роди Кикема щитки для ног в шкафу в раздевалке и корзинка со сладостями в столовой 34 У Вонючки Роуча огромные руки 35 Он говорит что постный пудинг это месиво в жиже 36 А как то раз он спросил  Как тебя зовут 37 Стивен ответил  Стивен Дедал 38 А Вонючка Роуч сказал  Что это за имя 39 И когда Стивен не нашелся что ответить Вонючка Роуч спросил  Кто твой отец 40 Стивен ответил  Джентльмен 41 Тогда Вонючка Роуч спросил  А он не мировой судья 42 Он топтался в самом хвосте своей команды делая иногда короткие перебежки 43 Руки его посинели от холода 44 Он засунул их в боковые карманы своей серой подпоясанной куртки 45 Пояс это такая штука над карманами 46 А вот в драке о тех кто победил говорят за пояс заткнул 47 Как то один мальчик сказал Кэнтуэллу 48 Я бы тебя мигом за пояс заткнул 49 А Кэнтуэлл ответил 50 Попробуй ка Сесила Сандера за пояс заткнуть 51 Я посмотрю как он тебе даст под зад 52 Так некрасиво выражаться 53 Мама сказала чтобы он не водился с грубыми мальчиками в колледже 54 Мама такая красивая 55 В первый день в приемной замка она когда прощалась с ним слегка подняла свою вуаль чтобы поцеловать его и нос и глаза у нее были красные 56 Но он притворился будто не замечает что она сейчас расплачется 57 Мама красивая но когда она плачет она уже не такая красивая 58 А папа дал ему два пятишиллинговика пусть у него будут карманные деньги 59 И папа сказал чтобы он написал домой если ему что нибудь понадобится и чтобы он ни в коем случае не ябедничал на товарищей 60 Потом у двери ректор пожал руки папе и маме и сутана его развевалась на ветру а коляска с папой и мамой стала отъезжать 61 Они махали руками и кричали ему из коляски Прощай Стивен прощай 62 Прощай Стивен прощай 63 Вокруг него началась свалка из за мяча и страшась этих горящих глаз и грязных башмаков он нагнулся и стал смотреть мальчикам под ноги 64 Они дрались пыхтели и ноги их топали толкались и брыкались 65 Потом желтые ботинки Джека Лотена наподдали мяч и все другие ботинки и ноги ринулись за ним 66 Он пробежал немножко и остановился 67 Не стоило бежать 68 Скоро все поедут домой 69 После ужина в классе он переправит число приклеенное у него в парте с семидесяти семи на семьдесят шесть 70 Лучше бы сейчас быть в классе чем здесь на холоде 71 Небо бледное и холодное а в главном здании в замке огни 72 Он думал из какого окна Гамильтон Роуэн бросил свою шляпу на изгородь и были ли тогда цветочные клумбы под окнами 73 Однажды когда он был в замке тамошний служитель показал ему следы солдатских пуль на двери и дал ореховый сухарик какие едят в общине 74 Как хорошо и тепло смотреть на огни в замке 75 Совсем как в книжке 76 Может быть Лестерское аббатство было такое 77 А какие хорошие фразы были в учебнике д ра Корнуэлла 78  Они похожи на стихи но это только примеры чтобы научиться писать правильно Уолси умер в Лестерском аббатстве Где погребли его аббаты Растения съедают черви Животных съедает рак Хорошо бы лежать сейчас на коврике у камина подперев голову руками и думать про себя об этих фразах 79 Он вздрогнул будто по телу пробежала холодная липкая вода 80 Подло было со стороны Уэллса столкнуть его в очко уборной за то что он не захотел обменять свою маленькую табакерку на игральную кость которой Уэллс выиграл сорок раз в бабки 81 Какая холодная и липкая была вода 82 А один мальчик раз видел как большая крыса прыгнула в жижу 83 Мама с Дэнти сидели у камина и дожидались когда Бриджет подаст чай 84 Мама поставила ноги на решетку и ее вышитые бисером ночные туфли нагрелись и от них так хорошо и тепло пахло 85 Дэнти знала массу всяких вещей 86 Она учила его где находится Мозамбикский пролив и какая самая длинная река в Америке и как называется самая высокая гора на Луне 87 Отец Арнолл знает больше чем Дэнти потому что он священник но папа и дядя Чарльз оба говорили что Дэнти умная и начитанная женщина 88 А иногда Дэнти делала такой звук после обеда и подносила руку ко рту это была отрыжка 89 Голос с дальнего конца площадки крикнул  Все домой 90 Потом голоса из младших и средних классов подхватили  Домой 91 Все домой 92 Мальчики сходились со всех сторон раскрасневшиеся и грязные и он шагал среди них радуясь что идут домой 93 Роди Кикем держал мяч за скользкую шнуровку 94 Один мальчик попросил поддать еще напоследок но он шел себе и даже ничего не ответил 95 Саймон Мунен сказал чтобы он этого не делал так как на них смотрит надзиратель 96 Тогда тот мальчик повернулся к Саймону Мунену и сказал Мы все знаем почему ты так говоришь 97 Ты известный подлиза 98 Какое странное слово подлиза 99 Мальчик обозвал так Саймона Мунена потому что Саймон Мунен связывал иногда фальшивые рукава на спине надзирателя Макглэйда а тот делал вид что сердится 100 Противный звук у этого слова 101 Однажды он мыл руки в уборной гостиницы на Уиклоу стрит а потом папа вынул пробку за цепочку и грязная вода стала стекать через отверстие в раковине 102 А когда она вся стекла потихоньку отверстие в раковине сделало такой звук длизс 103 Только громче 104 Он вспоминал это и белые стены уборной и ему делалось сначала холодно а потом жарко 105 Ему сделалось сначала холодно а потом чуть чуть жарко 106 И он видел слова напечатанные на кранах 107 В этом что то было чудное 108 В коридоре был тоже холодный воздух 109 Он был сыроватый и чудной 110 Но скоро зажгут газ и он будет тихонечко так петь точно какую то песенку 111 Все одну и ту же и когда мальчики не шумят в рекреационном зале ее слышно 112 Урок арифметики начался 113 Отец Арнолл написал на доске трудный пример и сказал  Ну кто победит 114 Живей Йорк 115 Живей Ланкастер 116 Стивен старался изо всех сил но пример был очень трудный и он сбился 117 Маленький шелковый значок с белой розой приколотый к его куртке на груди начал дрожать 118 Он был не очень силен в арифметике но старался изо всех сил чтобы Йорки не проиграли 119 Отец Арнолл сделал очень строгое лицо но он вовсе не сердился он смеялся 120 Вдруг Джек Лотен хрустнул пальцами и отец Арнолл посмотрел в его тетрадку и сказал Верно 121 Браво Ланкастер 122 Алая роза победила 123 Не отставай Йорк 124 Ну ка поднатужьтесь 125 Джек Лотен поглядывал на них со своего места 126 Маленький шелковый значок с алой розой казался очень нарядным на его синей матроске 127 Стивен почувствовал что его лицо тоже покраснело когда он вспомнил как мальчики держали пари кто будет первым учеником Джек Лотен или он 128 Были недели когда Джек Лотен получал билет первого ученика а были недели когда он получал билет первого ученика 129 Его белый шелковый значок дрожал и дрожал все время пока он решал следующий пример и слушал голос отца Арнолла 130 Потом все его рвение пропало и он почувствовал как лицо у него сразу похолодело 131 Он подумал что оно должно быть стало совсем белым раз так похолодело 132 Он не мог решить пример но это было не важно 133 Белые розы и алые розы какие красивые цвета 134 И билеты первого второго и третьего ученика тоже очень красивые розовые бледно желтые и сиреневые 135 Бледно желтые сиреневые и розовые розы тоже красивые 136 Может быть дикие розы как раз такие и ему вспомнилась песенка о цветах дикой розы на зеленом лугу 137 А вот зеленых роз не бывает'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eab35ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import configs, build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e84a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 14:15:53.334 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/v1/ner/ner_rus_bert_torch_new.tar.gz to C:\\Users\\Ирина\\.deeppavlov\\models\\ner_rus_bert_torch_new.tar.gz\n",
      "2023-05-18 14:15:54.25 WARNING in 'deeppavlov.core.data.utils'['utils'] at line 114: Found a partial download C:\\Users\\Ирина\\.deeppavlov\\models\\ner_rus_bert_torch_new.tar.gz.part\n",
      " 56%|████████████████████████████████████████████████▏                                     | 808M/1.44G [00:00<?, ?B/s]2023-05-18 14:15:54.35 WARNING in 'deeppavlov.core.data.utils'['utils'] at line 118: Download stopped abruptly, trying to resume from 807534592 to reach 1440917530\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.44G/1.44G [09:58<00:00, 1.06MB/s]\n",
      "2023-05-18 14:25:52.116 INFO in 'deeppavlov.core.data.utils'['utils'] at line 276: Extracting C:\\Users\\Ирина\\.deeppavlov\\models\\ner_rus_bert_torch_new.tar.gz archive into C:\\Users\\Ирина\\.deeppavlov\\models\\ner_rus_bert_torch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6db9524b0e4412e89c5bc1278fbe70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ирина\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4256b1cd10b4a87bd7d84f0519f756b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf4e176df27496bacd4a434b630e9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3602d585d7984c7a9ec5a379a7352e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1ec4f8fd3d415383ad0cde38f7a758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ner_model = build_model(configs.ner.ner_rus_bert, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "339d2a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 512\n",
    "chunks = [for_models[i:i+n] for i in range(0, len(for_models), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e3b1d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_bert = []\n",
    "for i in chunks:\n",
    "    doc_bert.append(ner_model([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "45ee8e83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bert = []\n",
    "for i in range(len(doc_bert)-1):\n",
    "    for j in range(len(doc_bert[i][0][0])):\n",
    "        for f in for_models.split(' '):\n",
    "            if f == doc_bert[i][0][0][j]:\n",
    "                if doc_bert[i][1][0][j] == 'O':\n",
    "                    df_bert.append(f + '-' + doc_bert[i][1][0][j])\n",
    "                else:\n",
    "                    df_bert.append(f + '-' + doc_bert[i][1][0][j][2:])\n",
    "                break\n",
    "            elif f == doc_bert[i][0][0][j] + doc_bert[i+1][0][0][0]:\n",
    "                df_bert.append(f + '-' + 'O')\n",
    "                break\n",
    "\n",
    "# отдельно рассмотреть последнее:\n",
    "#for i in range(1, len(doc_bert[-1][0][0])):\n",
    "#    df_bert.append(doc_bert[-1][0][0][i] + '-' + doc_bert[-1][1][0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "eb703a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = []\n",
    "for i in df_bert:\n",
    "    if i.split('-')[1] == 'O':\n",
    "        bert.append('')\n",
    "    else:\n",
    "        bert.append(i.split('-')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14911c1",
   "metadata": {},
   "source": [
    "### Dataset with all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c49b43cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_alltags = pd.DataFrame({'ru': ru_full_tags, 'en': en_full_tags, 'en_tag': en_tag_full_tags, 'natasha': natasha, 'stanza': stanza, 'bert': bert})\n",
    "df_alltags.to_excel('./all_entities.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82040335",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "8431c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alltags = pd.read_excel('all_entities.xlsx', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6e273a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6e502c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tag = []\n",
    "for i in df_alltags['en_tag']:\n",
    "    if str(i) == 'nan':\n",
    "        en_tag.append('')\n",
    "    else:\n",
    "        en_tag.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da909ff8",
   "metadata": {},
   "source": [
    "### Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "eaa892dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "natasha_tag = []\n",
    "for i in df_alltags['natasha']:\n",
    "    if str(i) == 'nan':\n",
    "        natasha_tag.append('')\n",
    "    else:\n",
    "        natasha_tag.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7d421569",
   "metadata": {},
   "outputs": [],
   "source": [
    "natasha_en_tag = []\n",
    "natasha_natasha_tag = []\n",
    "for i in range(len(en_tag)):\n",
    "    if en_tag[i] == 'GPE':\n",
    "        natasha_en_tag.append('LOC')\n",
    "        natasha_natasha_tag.append(natasha_tag[i])\n",
    "    elif en_tag[i] != '' and natasha_tag[i] != '' and en_tag[i] != 'FAC' and en_tag[i] != 'VEH':\n",
    "        natasha_en_tag.append(en_tag[i])\n",
    "        natasha_natasha_tag.append(natasha_tag[i])\n",
    "    elif (en_tag[i] == '' and natasha_tag[i] != '') or (en_tag[i] != '' and natasha_tag[i] == '' and en_tag[i] != 'FAC' and en_tag[i] != 'VEH'):\n",
    "        natasha_en_tag.append(en_tag[i])\n",
    "        natasha_natasha_tag.append(natasha_tag[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9763abda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00        43\n",
      "         LOC       0.43      0.25      0.32        12\n",
      "         PER       0.65      0.33      0.44       218\n",
      "\n",
      "    accuracy                           0.28       273\n",
      "   macro avg       0.36      0.19      0.25       273\n",
      "weighted avg       0.54      0.28      0.37       273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(natasha_en_tag, natasha_natasha_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b41428",
   "metadata": {},
   "source": [
    "### Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "14cfc7d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stanza_tag = []\n",
    "for i in df_alltags['stanza']:\n",
    "    if str(i) == 'nan':\n",
    "        stanza_tag.append('')\n",
    "    else:\n",
    "        stanza_tag.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e5d6b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza_en_tag = []\n",
    "stanza_stanza_tag = []\n",
    "for i in range(len(en_tag)):\n",
    "    if stanza_tag == 'MISC' and en_tag[i] != '':\n",
    "        stanza_en_tag.append(en_tag[i])\n",
    "        stanza_stanza_tag.append(en_tag[i])\n",
    "    elif en_tag[i] == 'GPE':\n",
    "        stanza_en_tag.append('LOC')\n",
    "        stanza_stanza_tag.append(stanza_tag[i])\n",
    "    elif en_tag[i] != '' and stanza_tag[i] != '' and en_tag[i] != 'FAC' and en_tag[i] != 'VEH':\n",
    "        stanza_en_tag.append(en_tag[i])\n",
    "        stanza_stanza_tag.append(stanza_tag[i])\n",
    "    elif (en_tag[i] == '' and stanza_tag[i] != '') or (en_tag[i] != '' and stanza_tag[i] == '' and en_tag[i] != 'FAC' and en_tag[i] != 'VEH'):\n",
    "        stanza_en_tag.append(en_tag[i])\n",
    "        stanza_stanza_tag.append(stanza_tag[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "711175c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00        70\n",
      "         LOC       0.50      0.25      0.33        12\n",
      "        MISC       0.00      0.00      0.00         0\n",
      "         PER       0.58      0.34      0.43       218\n",
      "\n",
      "    accuracy                           0.26       300\n",
      "   macro avg       0.27      0.15      0.19       300\n",
      "weighted avg       0.44      0.26      0.33       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(stanza_en_tag, stanza_stanza_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afaa00e",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "7c420d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tag = []\n",
    "for i in df_alltags['bert']:\n",
    "    if str(i) == 'nan':\n",
    "        bert_tag.append('')\n",
    "    else:\n",
    "        bert_tag.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "5cd4f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_en_tag = []\n",
    "bert_bert_tag = []\n",
    "for i in range(len(en_tag)):\n",
    "    if en_tag[i] == 'GPE':\n",
    "        bert_en_tag.append('LOC')\n",
    "        bert_bert_tag.append(bert_tag[i])\n",
    "    elif en_tag[i] != '' and bert_tag[i] != '' and en_tag[i] != 'FAC' and en_tag[i] != 'VEH':\n",
    "        bert_en_tag.append(en_tag[i])\n",
    "        bert_bert_tag.append(bert_tag[i])\n",
    "    elif (en_tag[i] == '' and bert_tag[i] != '') or (en_tag[i] != '' and bert_tag[i] == '' and en_tag[i] != 'FAC' and en_tag[i] != 'VEH'):\n",
    "        bert_en_tag.append(en_tag[i])\n",
    "        bert_bert_tag.append(bert_tag[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c688160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "                   0.00      0.00      0.00        33\n",
      "         LOC       0.50      0.25      0.33        12\n",
      "         PER       0.68      0.29      0.41       218\n",
      "\n",
      "    accuracy                           0.25       263\n",
      "   macro avg       0.39      0.18      0.25       263\n",
      "weighted avg       0.59      0.25      0.36       263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(bert_en_tag, bert_bert_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb739ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
